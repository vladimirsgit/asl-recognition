@misc{article_dataset0,
	title = {The American Sign Language alphabet},
	year = {2024},
	author = {Olewniczak, Szymon and Witczak, Kacper and Czartowski, Iwo and Wo{\l}ek, Henryk},
	doi = {10.34808/ctjj-fw17},
	url = {https://mostwiedzy.pl/en/open-research-data/the-american-sign-language-alphabet,730112114714428-0},
}

@misc{kaggle_dataset0,
  author       = {Angel G. Ortiz},
  title        = {American Sign Language},
  year         = {2022},
  howpublished = {\url{https://www.kaggle.com/datasets/angelgortiz/american-sign-language}},
  note         = {Accesat: 01.02.2025}
}

@misc{article_dataset1,
  author       = {Ahmed Sowrow and Ab. Rahim and Md Iftekhar Alam Sarker Iftekhar and Sadia Islam Prova and Mohammad Rezwanul Huq},
  title        = {Images of American Sign Language (ASL) Alphabet Gestures},
  year         = {2024},
  howpublished = {https://data.mendeley.com/datasets/48dg9vhmyk/2},
  doi          = {10.17632/48dg9vhmyk.2},
  note         = {Accesat: 01.02.2025},
  url          = {https://doi.org/10.17632/48dg9vhmyk.2}
}

@misc{article_dataset2,
doi = {10.21227/gzpc-k936},
url = {https://dx.doi.org/10.21227/gzpc-k936},
author = {Raimundo Farrapo Pinto Junior and Ialis Cavalvante de Paula Junior},
publisher = {IEEE Dataport},
title = {Static Hand Gesture ASL Dataset},
year = {2019} }

@misc{kaggle_dataset1,
  author       = {Jerome Kingsly},
  title        = { American Sign Language (ASL) Alphabet Dataset},
  year         = {2022},
  howpublished = {\url{https://www.kaggle.com/datasets/jeromekingsly/sign-language-recognition-using-computer-vision}},
  note         = {Accesat: 01.02.2025}
}

@inproceedings{article_dataset3,
  title={Spelling it out: Real-time ASL fingerspelling recognition},
  author={Pugeault, Nicolas and Bowden, Richard},
  booktitle={2011 IEEE International conference on computer vision workshops (ICCV workshops)},
  pages={1114--1119},
  year={2011},
  organization={Ieee}
}

@misc{kaggle_dataset2,
  author       = {SigNN Team},
  title        = {ASL Sign Language Alphabet Pictures [Minus J, Z]},
  year         = {2020},
  howpublished = {\url{https://www.kaggle.com/datasets/signnteam/asl-sign-language-pictures-minus-j-z}},
  note         = {Accesat: 01.02.2025}
}

@misc{kaggle_dataset3,
  author       = {Kapil Londhe},
  title        = {American Sign Language},
  year         = {2021},
  howpublished = {\url{https://www.kaggle.com/datasets/kapillondhe/american-sign-language}},
  note         = {Accesat: 01.02.2025}
}
@misc{kaggle_dataset4,
  author       = {Jordi Viader},
  title        = {American Sign Language Alphabet (Static)},
  year         = {2020},
  howpublished = {\url{https://www.kaggle.com/datasets/jordiviader/american-sign-language-alphabet-static}},
  note         = {Accesat: 01.02.2025}
}

@misc{article_dataset4,
  author       = {Miguel Rivera},
  title        = {ASLYset},
  year         = {2019},
  howpublished = {https://data.mendeley.com/datasets/xs6mvhx6rh/1},
  doi          = {10.17632/xs6mvhx6rh.1},
  note         = {Accesat: 01.02.2025}
}

@misc{youtube_dataset0,
  author = {Deirdre Wade},
  title = {ASL Alphabet for Dummies (i.e., hearing people)},
  year = {2020},
  howpublished = {\url{https://www.youtube.com/watch?v=SejtedO_MJk}},
  note = {Video, licențiat sub Creative Commons Attribution}
}

@misc{youtube_dataset1,
  author = {Moniciai Smith},
  title = {Asl sign language: Learning how to sign the alphabet},
  year = {2020},
  howpublished = {\url{https://www.youtube.com/watch?v=8XgYji7WFuY}},
  note = {Video, licențiat sub Creative Commons Attribution}
}

@misc{youtube_dataset2,
  author = {Sydnee Stokes},
  title = {Alphabet in Sign Language Edited},
  year = {2018},
  howpublished = {\url{https://www.youtube.com/watch?v=U4M_xh-g7EM}},
  note = {Video, licențiat sub Creative Commons Attribution}
}

@misc{asl_alphabet_chart,
  author       = {{American Society for Deaf Children}},
  title        = {Free ASL Alphabet Chart},
  year         = {2019},
  howpublished = {\url{https://deafchildren.org/2019/06/free-asl-alphabet-chart/}},
  note         = {Accesat: 01.02.2025}
}

@manual{python312,
  title={{Python: A dynamic, open source programming language}},
  author={{Python Core Team}},
  organization={{Python Software Foundation}},
  year={2023},
  url={https://www.python.org/},
  note={Python version 3.12}
}

@article{opencv_library,
    author = {Bradski, G.},
    citeulike-article-id = {2236121},
    journal = {Dr. Dobb's Journal of Software Tools},
    keywords = {bibtex-import},
    posted-at = {2008-01-15 19:21:54},
    priority = {4},
    title = {{The OpenCV Library}},
    year = {2000}
}

@misc{zhang2020mediapipehandsondevicerealtime,
      title={MediaPipe Hands: On-device Real-time Hand Tracking}, 
      author={Fan Zhang and Valentin Bazarevsky and Andrey Vakunov and Andrei Tkachenka and George Sung and Chuo-Ling Chang and Matthias Grundmann},
      year={2020},
      eprint={2006.10214},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2006.10214}, 
}

@software{haris_iqbal_2018_2526396,
  author       = {Haris Iqbal},
  title        = {HarisIqbal88/PlotNeuralNet v1.0.0},
  month        = dec,
  year         = 2018,
  publisher    = {Zenodo},
  version      = {v1.0.0},
  doi          = {10.5281/zenodo.2526396},
  url          = {https://doi.org/10.5281/zenodo.2526396},
}

@INPROCEEDINGS{data_augment1,
  author={Shijie, Jia and Ping, Wang and Peiyi, Jia and Siping, Hu},
  booktitle={2017 Chinese Automation Congress (CAC)}, 
  title={Research on data augmentation for image classification based on convolution neural networks}, 
  year={2017},
  volume={},
  number={},
  pages={4165-4170},
  keywords={Training;Convolution;Image classification;Data models;Neural networks;Training data;Image Classification;Data Augmentation;Convolution Neural network},
  doi={10.1109/CAC.2017.8243510}}

@inproceedings{data_augment2,
  author    = {Kevin McGuinness and Sarah O'Gara},
  title     = {Comparing Data Augmentation Strategies for Deep Image Classification},
  booktitle = {Proceedings of the Irish Machine Vision and Image Processing Conference (IMVIP)},
  year      = {2019},
  pages     = {},
  address   = {Dublin, Ireland},
  month     = {August},
  isbn      = {978-0-9934207-4-0}
}
@InProceedings{cutmix,
author = {Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
title = {CutMix: Regularization Strategy to Train Strong Classifiers With Localizable Features},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019}
} 



@article{mixup,
  author       = {Hongyi Zhang and
                  Moustapha Ciss{\'{e}} and
                  Yann N. Dauphin and
                  David Lopez{-}Paz},
  title        = {mixup: Beyond Empirical Risk Minimization},
  journal      = {CoRR},
  volume       = {abs/1710.09412},
  year         = {2017},
  url          = {http://arxiv.org/abs/1710.09412},
  eprinttype    = {arXiv},
  eprint       = {1710.09412},
  timestamp    = {Mon, 13 Aug 2018 16:47:14 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1710-09412.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@Article{albumentations,
AUTHOR = {Buslaev, Alexander and Iglovikov, Vladimir I. and Khvedchenya, Eugene and Parinov, Alex and Druzhinin, Mikhail and Kalinin, Alexandr A.},
TITLE = {Albumentations: Fast and Flexible Image Augmentations},
JOURNAL = {Information},
VOLUME = {11},
YEAR = {2020},
NUMBER = {2},
ARTICLE-NUMBER = {125},
URL = {https://www.mdpi.com/2078-2489/11/2/125},
ISSN = {2078-2489},
ABSTRACT = {Data augmentation is a commonly used technique for increasing both the size and the diversity of labeled training sets by leveraging input transformations that preserve corresponding output labels. In computer vision, image augmentations have become a common implicit regularization technique to combat overfitting in deep learning models and are ubiquitously used to improve performance. While most deep learning frameworks implement basic image transformations, the list is typically limited to some variations of flipping, rotating, scaling, and cropping. Moreover, image processing speed varies in existing image augmentation libraries. We present Albumentations, a fast and flexible open source library for image augmentation with many various image transform operations available that is also an easy-to-use wrapper around other augmentation libraries. We discuss the design principles that drove the implementation of Albumentations and give an overview of the key features and distinct capabilities. Finally, we provide examples of image augmentations for different computer vision tasks and demonstrate that Albumentations is faster than other commonly used image augmentation tools on most image transform operations.},
DOI = {10.3390/info11020125}
}

@software{torchvision2016,
    title        = {TorchVision: PyTorch's Computer Vision library},
    author       = {TorchVision maintainers and contributors},
    year         = 2016,
    journal      = {GitHub repository},
    publisher    = {GitHub},
    howpublished = {\url{https://github.com/pytorch/vision}}
}

@misc{pytorch,
      title={PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
      author={Adam Paszke and Sam Gross and Francisco Massa and Adam Lerer and James Bradbury and Gregory Chanan and Trevor Killeen and Zeming Lin and Natalia Gimelshein and Luca Antiga and Alban Desmaison and Andreas Köpf and Edward Yang and Zach DeVito and Martin Raison and Alykhan Tejani and Sasank Chilamkurthy and Benoit Steiner and Lu Fang and Junjie Bai and Soumith Chintala},
      year={2019},
      eprint={1912.01703},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1912.01703}, 
}

@inproceedings{batch_norm,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={pmlr}
}

@inproceedings{relu1,
  title={Comparative study of convolution neural network’s relu and leaky-relu activation functions},
  author={Dubey, Arun Kumar and Jain, Vanita},
  booktitle={Applications of Computing, Automation and Wireless Systems in Electrical Engineering: Proceedings of MARC 2018},
  pages={873--880},
  year={2019},
  organization={Springer}
}

@article{relu2,
  title={Investigating the Impact of ReLU and Sigmoid Activation Functions on Animal Classification Using CNN Models},
  author={Mesran, M and Yahya, Sitti Rachmawati and Nugroho, Fifto and Windarto, Agus Perdana and others},
  journal={Jurnal RESTI (Rekayasa Sistem dan Teknologi Informasi)},
  volume={8},
  number={1},
  pages={111--118},
  year={2024}
}


@article{vggnet,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{dropout1,
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
title = {Dropout: a simple way to prevent neural networks from overfitting},
year = {2014},
issue_date = {January 2014},
publisher = {JMLR.org},
volume = {15},
number = {1},
issn = {1532-4435},
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different "thinned" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {1929–1958},
numpages = {30},
keywords = {deep learning, model combination, neural networks, regularization}
}

@article{dropout2,
  title={A survey of regularization strategies for deep models},
  author={Moradi, Reza and Berangi, Reza and Minaei, Behrouz},
  journal={Artificial Intelligence Review},
  volume={53},
  number={6},
  pages={3947--3986},
  year={2020},
  publisher={Springer}
}



@article{label_smooth,
  author       = {Christian Szegedy and
                  Vincent Vanhoucke and
                  Sergey Ioffe and
                  Jonathon Shlens and
                  Zbigniew Wojna},
  title        = {Rethinking the Inception Architecture for Computer Vision},
  journal      = {CoRR},
  volume       = {abs/1512.00567},
  year         = {2015},
  url          = {http://arxiv.org/abs/1512.00567},
  eprinttype    = {arXiv},
  eprint       = {1512.00567},
  timestamp    = {Mon, 13 Aug 2018 16:49:07 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/SzegedyVISW15.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@misc{adamw_article,
      title={Decoupled Weight Decay Regularization}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2019},
      eprint={1711.05101},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.05101}, 
}


@InProceedings{momentum1,
  title = 	 {On the importance of initialization and momentum in deep learning},
  author = 	 {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {1139--1147},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  number =       {3},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/sutskever13.pdf},
  url = 	 {https://proceedings.mlr.press/v28/sutskever13.html},
  abstract = 	 {Deep and recurrent neural networks (DNNs and RNNs respectively) are powerful models that were considered to be almost impossible to train using stochastic gradient descent with momentum. In this paper, we show that when stochastic gradient descent with momentum uses a well-designed random initialization and a particular type of slowly increasing schedule for the momentum parameter, it can train both DNNs and RNNs (on datasets with long-term dependencies) to levels of performance that were previously achievable only with Hessian-Free optimization. We find that both the initialization and the momentum are crucial since poorly initialized networks cannot be trained with momentum and well-initialized networks perform markedly worse when the momentum is absent or poorly tuned.     Our success training these models suggests that previous attempts to train deep and recurrent neural networks from random initializations have likely failed due to poor initialization schemes. Furthermore, carefully tuned momentum methods suffice for dealing with the curvature issues in deep and recurrent network training objectives without the need for sophisticated second-order methods.   }
}


@misc{adam_article,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2017},
      eprint={1412.6980},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1412.6980}, 
}

@inproceedings{kaiming_w_init,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}


@article{scikit-learn,
  title={Scikit-learn: Machine Learning in {P}ython},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
          and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
          and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
          Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

@Article{matplotlib,
  Author    = {Hunter, J. D.},
  Title     = {Matplotlib: A 2D graphics environment},
  Journal   = {Computing in Science \& Engineering},
  Volume    = {9},
  Number    = {3},
  Pages     = {90--95},
  abstract  = {Matplotlib is a 2D graphics package used for Python for
  application development, interactive scripting, and publication-quality
  image generation across user interfaces and operating systems.},
  publisher = {IEEE COMPUTER SOC},
  doi       = {10.1109/MCSE.2007.55},
  year      = 2007
}

@article{seaborn,
    doi = {10.21105/joss.03021},
    url = {https://doi.org/10.21105/joss.03021},
    year = {2021},
    publisher = {The Open Journal},
    volume = {6},
    number = {60},
    pages = {3021},
    author = {Michael L. Waskom},
    title = {seaborn: statistical data visualization},
    journal = {Journal of Open Source Software}
 }

@misc{colab,
  title = {Google Colaboratory},
  author = {{Google}},
  year = {2023},
  url = {https://colab.research.google.com/}
}

@misc{kotlin,
  author       = {JetBrains},
  title        = {Kotlin Programming Language},
  year         = {2011},
  howpublished = {\url{https://kotlinlang.org}},
}

@misc{retrofit,
  title        = {Retrofit},
  author       = {Square, Inc.},
  year         = {2013},
  howpublished = {\url{https://square.github.io/retrofit/}},
  note         = {Accesat: 01.06.2025}
}

@misc{camerax,
  title        = {CameraX: Jetpack support library for camera app development},
  author       = {Android Developers},
  year         = {2019},
  howpublished = {\url{https://developer.android.com/training/camerax}},
  note         = {Accesat: 01.06.2025}
}


@misc{jwt,
    series =    {Request for Comments},
    number =    7519,
    howpublished =  {RFC 7519},
    publisher = {RFC Editor},
    doi =       {10.17487/RFC7519},
    url =       {https://www.rfc-editor.org/info/rfc7519},
    author =    {Michael B. Jones and John Bradley and Nat Sakimura},
    title =     {{JSON Web Token (JWT)}},
    pagetotal = 30,
    year =      2015,
    month =     may,
    abstract =  {JSON Web Token (JWT) is a compact, URL-safe means of representing claims to be transferred between two parties. The claims in a JWT are encoded as a JSON object that is used as the payload of a JSON Web Signature (JWS) structure or as the plaintext of a JSON Web Encryption (JWE) structure, enabling the claims to be digitally signed or integrity protected with a Message Authentication Code (MAC) and/or encrypted.},
}

@misc{fastapi,
  author       = {Sebastián Ramírez},
  title        = {FastAPI: Fast and efficient web framework for building APIs with Python 3.6+},
  year         = {2018},
  howpublished = {\url{https://fastapi.tiangolo.com/}},
  note         = {Accesat: 01.06.2025}
}

@article{docker,
  title={Docker: lightweight linux containers for consistent development and deployment},
  author={Merkel, Dirk},
  journal={Linux journal},
  volume={2014},
  number={239},
  pages={2},
  year={2014}
}

@misc{uvicorn,
  author       = {Tom Christie},
  title        = {Uvicorn: The lightning-fast ASGI server},
  year         = {2018},
  howpublished = {\url{https://www.uvicorn.org/}},
  note         = {Accesat: 01.06.2025}
}

@misc{redis,
  author       = {Salvatore Sanfilippo and Redis contributors},
  title        = {Redis: In-memory data structure store},
  year         = {2009},
  howpublished = {\url{https://redis.io/}},
  note         = {{Accesat: 01.06.2025}}
}

@misc{postgresql,
  author       = {The PostgreSQL Global Development Group},
  title        = {PostgreSQL: The world's most advanced open source relational database},
  year         = {1996},
  howpublished = {\url{https://www.postgresql.org/}},
  note         = {Accesat: 01.06.2025}
}

@misc{nginx,
  author       = {Igor Sysoev and Nginx, Inc.},
  title        = {NGINX: High-performance HTTP server and reverse proxy},
  year         = {2004},
  howpublished = {\url{https://nginx.org/}},
  note         = {Accesat: 01.06.2025}
}

@misc{asyncpg,
  author       = {MagicStack Inc.},
  title        = {asyncpg: A fast PostgreSQL Database Client Library for Python/asyncio},
  year         = {2016},
  howpublished = {\url{https://github.com/MagicStack/asyncpg}},
  note         = {Accesat: 01.06.2025}
}

@misc{sqlmodel,
  author       = {Sebastián Ramírez},
  title        = {SQLModel: SQL Databases in Python, designed for simplicity, compatibility, and robustness},
  year         = {2021},
  howpublished = {\url{https://sqlmodel.tiangolo.com/}},
  note         = {Accesat: 01.06.2025}
}


@misc{email_validator,
  author       = {Joshua Tauberer},
  title        = {email-validator: A robust email syntax and deliverability validator},
  year         = {2018},
  howpublished = {\url{https://github.com/JoshData/python-email-validator}},
  note         = {Accesat: 01.06.2025}
}

@misc{bcrypt,
  author       = {The Python Cryptographic Authority},
  title        = {bcrypt: Modern password hashing for Python},
  year         = {2012},
  howpublished = {\url{https://github.com/pyca/bcrypt}},
  note         = {Accesat: 01.06.2025}
}

@misc{mobilenetv3,
      title={Searching for MobileNetV3}, 
      author={Andrew Howard and Mark Sandler and Grace Chu and Liang-Chieh Chen and Bo Chen and Mingxing Tan and Weijun Wang and Yukun Zhu and Ruoming Pang and Vijay Vasudevan and Quoc V. Le and Hartwig Adam},
      year={2019},
      eprint={1905.02244},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1905.02244}, 
}

@misc{jetpackcompose,
  author       = {{Google Developers}},
  title        = {{Jetpack Compose}},
  year         = {2024},
  howpublished = {\url{https://developer.android.com/jetpack/compose}},
  note         = {Accesat: 01.06.2025}
}
